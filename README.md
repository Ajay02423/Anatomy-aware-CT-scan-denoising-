# ğŸ¥ Anatomy-Aware CT Scan Denoising

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Advanced Deep Learning Approaches for Radiation Dose Reduction in Medical Imaging**

This repository contains a comprehensive collection of state-of-the-art deep learning models for CT scan denoising with anatomy-aware processing. Our approach enables significant radiation dose reduction while maintaining diagnostic image quality.

---

## ğŸ¯ Project Overview

Low-dose CT imaging is crucial for reducing radiation exposure in patients, but it introduces noise and artifacts that degrade image quality. This project implements and compares multiple deep learning architectures to perform anatomy-aware denoising on low-dose CT scans across different radiation dose levels.

### Key Features

âœ… **Multi-Model Architecture**: Compare 6 different deep learning models  
âœ… **Multi-Dose Evaluation**: Evaluate performance across 4 radiation dose levels (10%, 25%, 50%, 70%)  
âœ… **Anatomy-Aware Processing**: Models trained with knowledge of anatomical structures  
âœ… **Comprehensive Metrics**: PSNR, SSIM, RMSE evaluation  
âœ… **Teacher-Student Training**: Knowledge distillation approach for improved performance  

---

## ğŸ“Š Repository Structure

```
Anatomy-aware-CT-scan-denoising/
â”œâ”€â”€ Baseline/                 # Basic Autoencoder Implementation
â”‚   â”œâ”€â”€ training_baseline.py  # Training script
â”‚   â”œâ”€â”€ evaluate_baseline.py  # Evaluation script
â”‚   â””â”€â”€ eval_images/          # Sample outputs
â”‚
â”œâ”€â”€ Nafnet/                   # NAFNet (Normalized Attention FNet)
â”‚   â”œâ”€â”€ train_nafnet_mlp.py   # MLP variant training
â”‚   â”œâ”€â”€ evaluate_nafnet.py    # Evaluation
â”‚   â””â”€â”€ eval_images_nafnet_mlp/
â”‚
â”œâ”€â”€ RadIMG+Nafnet/            # RAD-IMG enhanced NAFNet
â”‚   â”œâ”€â”€ train_nafnet_radimg.py
â”‚   â”œâ”€â”€ evaluate_rad.py
â”‚   â””â”€â”€ eval_images_rad_mlp/
â”‚
â”œâ”€â”€ Resnet/                   # ResNet-based Architecture
â”‚   â”œâ”€â”€ train_resnet.py
â”‚   â”œâ”€â”€ evaluate_resnet.py
â”‚   â””â”€â”€ eval_images_resnet/
â”‚
â”œâ”€â”€ unet/                     # U-Net Architecture
â”‚   â”œâ”€â”€ train_unet.py
â”‚   â”œâ”€â”€ evaluate_unet.py
â”‚   â””â”€â”€ eval_images_unet/
â”‚
â”œâ”€â”€ Wo_dose/                  # Ablation Study (Without Dose)
â”‚   â”œâ”€â”€ train_wodose.py
â”‚   â”œâ”€â”€ evaluate_no_dose.py
â”‚   â””â”€â”€ eval_images_ablation/
â”‚
â”œâ”€â”€ Noise Simulation/         # Data Preparation
â”‚   â”œâ”€â”€ data_LoD0.py          # Low-dose simulation
â”‚   â””â”€â”€ data_mayo.py          # Mayo clinic data processing
â”‚
â”œâ”€â”€ Results/                  # Model Comparison Results
â”‚   â”œâ”€â”€ model_comparisons.md
â”‚   â”œâ”€â”€ metrics_summary.csv
â”‚   â””â”€â”€ visualizations/
â”‚
â”œâ”€â”€ Presentation - Anatomy-Aware Denoising.pdf
â””â”€â”€ README.md
```

---

## ğŸ§  Implemented Models

| Model | Architecture | Parameters | Focus Area |
|-------|-------------|-----------|------------|
| **Baseline** | Autoencoder | Conv + Deconv | Foundation model |
| **NAFNet** | Normalized Attention FNet | Attention-based | Feature refinement |
| **RAD-IMG + NAFNet** | NAFNet + RadIMG | Enhanced attention | Anatomy-aware processing |
| **ResNet** | Residual Networks | Skip connections | Deep feature learning |
| **U-Net** | Encoder-Decoder | Dense connections | Semantic segmentation-style |
| **Wo_Dose** | No dose conditioning | Ablation baseline | Performance impact analysis |

---

## ğŸ“ˆ Performance Metrics

Our models are evaluated on the following metrics:

- **PSNR (Peak Signal-to-Noise Ratio)**: Higher is better (typical range: 20-40 dB)
- **SSIM (Structural Similarity Index)**: Range [0,1], higher indicates better structural preservation
- **RMSE (Root Mean Square Error)**: Lower is better
- **MSE (Mean Square Error)**: Pixel-level error measurement

### Evaluation by Radiation Dose

Models are tested across 4 dose levels:
- **10% Dose**: Extreme noise reduction scenario
- **25% Dose**: Challenging noise environment
- **50% Dose**: Moderate dose level
- **70% Dose**: Near-standard dose

---

## ğŸš€ Training Pipeline

### Model Training

The teacher network is trained on normal-dose CT (NDCT) images:

```python
python Baseline/training_baseline.py \
    --mayo_root /path/to/data \
    --epochs_teacher 100 \
    --batch 8 \
    --lr 2e-4
    --epochs_student 150 \
    --lam_lat 1.0 \
    --lam_rec 1.0
```



## ğŸ“¥ Installation

### Requirements

- Python 3.8 or higher
- PyTorch 1.9+
- NumPy, Pillow, tqdm
- TensorBoard for visualization

### Setup

```bash
# Clone the repository
git clone https://github.com/Ajay02423/Anatomy-aware-CT-scan-denoising.git
cd Anatomy-aware-CT-scan-denoising

# Install dependencies
pip install torch torchvision
pip install numpy pillow tqdm tensorboard
```

---

## ğŸ“ Training Configuration

Key hyperparameters used across models:

| Parameter | Value | Description |
|-----------|-------|-------------|
| Batch Size | 8 | Samples per iteration |
| Learning Rate | 2e-4 | Adam optimizer |
| Teacher Epochs | 100 | NDCT autoencoder training |
| Student Epochs | 150 | LDCT encoder training |
| Î±_SSIM | 0.2 | SSIM loss weight |
| Î»_lat | 1.0 | Latent space loss weight |
| Î»_rec | 1.0 | Reconstruction loss weight |

---

## ğŸ“Š Normalization Strategy

Images are normalized using fixed windowing:

```python
MIN_HU = -1000.0  # Minimum Hounsfield Unit
MAX_HU = 1000.0   # Maximum Hounsfield Unit
# Normalize to [0, 1] then to [-1, 1] for Tanh activation
```

---

## ğŸ” Loss Functions

### Teacher Training
```
Loss = L1_Loss + Î±_SSIM Ã— (1 - SSIM)
```

### Student Training
```
Loss = Î»_lat Ã— MSE_Latent + Î»_rec Ã— L1_Reconstruction
```

---

## ğŸ“ Dataset Information

The project uses:
- **LDCT Pairs Dataset**: Low-dose and Normal-dose CT scan pairs
- **Doses**: 10%, 25%, 50%, 70% of standard radiation
- **Format**: .npy files with Hounsfield Unit values
- **Normalization**: Per-sample HU windowing

---

## ğŸ¨ Results & Visualization

Sample outputs are saved in each model folder:
- `training_samples/`: Progressive training visualization
- `eval_images/`: Model evaluation results
- `dose_wise_results/`: Performance per radiation dose

---

## ğŸ“š Model Training Details

### Baseline Encoder Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input (1, H, W)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Conv Block (1 â†’ 64)                 â”‚
â”‚ MaxPool â†’ Conv Block (64 â†’ 128)     â”‚
â”‚ MaxPool â†’ Conv Block (128 â†’ 256)    â”‚
â”‚ MaxPool â†’ Conv Block (256 â†’ 512)    â”‚
â”‚ MaxPool â†’ Conv Block (512 â†’ 512)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ Latent Space
```

### Baseline Decoder Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Latent (512, h, w)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DeconvBlock (512 â†’ 512)             â”‚
â”‚ ConvBlock â†’ DeconvBlock (512 â†’ 256) â”‚
â”‚ ConvBlock â†’ DeconvBlock (256 â†’ 128) â”‚
â”‚ ConvBlock â†’ DeconvBlock (128 â†’ 64)  â”‚
â”‚ Conv (64 â†’ 1) + Tanh                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Key Findings

1. **Dose Dependency**: Model performance scales with radiation dose
2. **Anatomy Awareness**: RAD-IMG enhancement shows consistent improvements
3. **Trade-offs**: Balance between noise reduction and detail preservation
4. **Generalization**: Models trained on one dose generalize reasonably to others

---

## ğŸ“– How to Evaluate

```bash
# Evaluate Baseline model
python Baseline/evaluate_baseline.py \
    --model_path runs/final/student \
    --test_data /path/to/test

# Evaluate NAFNet
python Nafnet/evaluate_nafnet.py \
    --model_path runs/final/student \
    --test_data /path/to/test
```

---

## ğŸ”„ Knowledge Distillation Approach

Our training uses a novel teacher-student framework:

1. **Teacher Network**: Learns to denoise normal-dose images
2. **Student Network**: Learns from teacher's latent representations
3. **Knowledge Transfer**: Minimize latent space divergence
4. **Dose Agnostic**: Student works across all dose levels

---

</div>
